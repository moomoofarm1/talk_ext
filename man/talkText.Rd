% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/1_talkText.R
\name{talkText}
\alias{talkText}
\title{Transform audio recordings to embeddings}
\usage{
talkText(
  talk_filepaths = talk_filepaths,
  model = "openai/whisper-small",
  device = "cpu",
  tokenizer_parallelism = FALSE,
  hg_gated = FALSE,
  hg_token = "",
  trust_remote_code = FALSE,
  logging_level = "warning"
)
}
\arguments{
\item{talk_filepaths}{(string) Path to a video file (.wav/) list of audio filepaths, each is embedded separately}

\item{model}{shortcut name for Hugging Face pretained model. Full list https://huggingface.co/transformers/pretrained_models.html}

\item{device}{(string) name of device: 'cpu', 'gpu', or 'gpu:k' where k is a specific device number}

\item{tokenizer_parallelism}{(boolean) whether to use device parallelization during tokenization.}

\item{hg_gated}{(boolean) Set to True if the model is gated}

\item{hg_token}{(string) The token to access the gated model got in huggingface website}

\item{trust_remote_code}{(boolean) use a model with custom code on the Huggingface Hub.}

\item{logging_level}{(string) Set logging level, options: "critical", "error", "warning", "info", "debug".}
}
\value{
A tibble with transcriptions.
}
\description{
Transform audio recordings to embeddings
}
\examples{
# Transform audio recordings in text:
# voice_data (included in talk-package), to embeddings.
\dontrun{
wav_path <- system.file("extdata/",
"test_short.wav",
package = "talk")
# Get transcription
talk_embeddings <- talkText(
wav_path
)
talk_embeddings
}
}
\seealso{
\code{\link{talkText}}.
}
